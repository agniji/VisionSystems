{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNnIJqKaMYy15eGB/f7HLU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agniji/VisionSystems/blob/main/Production_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "pjaPdVFlpZsS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbfdpw-UpPzs"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python torch torchvision numpy PySpin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Python Script for Real-Time Inference (production_inference.py)"
      ],
      "metadata": {
        "id": "uWS4LMU9pRu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import PySpin\n",
        "\n",
        "# Load the trained model (TorchScript format for portability)\n",
        "MODEL_PATH = \"model.pt\"\n",
        "model = torch.jit.load(MODEL_PATH)\n",
        "model.eval()\n",
        "\n",
        "# Initialize FLIR camera\n",
        "def initialize_camera():\n",
        "    system = PySpin.System.GetInstance()\n",
        "    cam_list = system.GetCameras()\n",
        "\n",
        "    if cam_list.GetSize() == 0:\n",
        "        print(\"No cameras detected!\")\n",
        "        system.ReleaseInstance()\n",
        "        return None, None\n",
        "\n",
        "    camera = cam_list.GetByIndex(0)\n",
        "    camera.Init()\n",
        "    return camera, system\n",
        "\n",
        "# Preprocess frame for model input\n",
        "def preprocess_frame(image):\n",
        "    image = cv2.resize(image, (224, 224))  # Adjust to your model's input size\n",
        "    image = np.transpose(image, (2, 0, 1))  # Convert HWC to CHW\n",
        "    image = image / 255.0  # Normalize\n",
        "    image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  # Add batch dim\n",
        "    return image\n",
        "\n",
        "# Main loop to capture and infer from camera feed\n",
        "def stream_and_infer():\n",
        "    camera, system = initialize_camera()\n",
        "    if camera is None:\n",
        "        return\n",
        "\n",
        "    print(\"Starting real-time inference...\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            # Capture image\n",
        "            image = camera.GetNextImage()\n",
        "            if image.IsIncomplete():\n",
        "                print(\"Image capture incomplete. Skipping frame.\")\n",
        "                continue\n",
        "\n",
        "            # Convert to OpenCV format\n",
        "            img_data = image.GetNDArray()\n",
        "            img_data = cv2.cvtColor(img_data, cv2.COLOR_BAYER_BG2RGB)  # Convert Bayer to RGB\n",
        "            image.Release()\n",
        "\n",
        "            # Preprocess and run inference\n",
        "            input_tensor = preprocess_frame(img_data)\n",
        "            with torch.no_grad():\n",
        "                output = model(input_tensor)\n",
        "\n",
        "            # Process model output (Modify as per your use case)\n",
        "            pred_label = torch.argmax(output).item()\n",
        "            confidence = torch.nn.functional.softmax(output, dim=1)[0, pred_label].item()\n",
        "            label_text = f\"Pred: {pred_label} ({confidence:.2f})\"\n",
        "\n",
        "            # Display results\n",
        "            cv2.putText(img_data, label_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        1, (0, 255, 0), 2)\n",
        "            cv2.imshow(\"Blackfly S - Real-Time Inference\", img_data)\n",
        "\n",
        "            # Exit on 'q' key\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "    finally:\n",
        "        camera.DeInit()\n",
        "        system.ReleaseInstance()\n",
        "        cv2.destroyAllWindows()\n",
        "        print(\"Camera released, resources cleaned.\")\n",
        "\n",
        "# Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    stream_and_infer()\n"
      ],
      "metadata": {
        "id": "wPDYNV8wpR_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Package it as an executable"
      ],
      "metadata": {
        "id": "eYGnZG3gpsGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pyinstaller --onefile production_inference.py"
      ],
      "metadata": {
        "id": "-Su4278np3vP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}